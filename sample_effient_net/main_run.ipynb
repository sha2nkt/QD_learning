{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aashi/penv/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "## Imports ##\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.distributions import Categorical\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import gym\n",
    "import numpy as np\n",
    "from itertools import count\n",
    "\n",
    "import logger \n",
    "\n",
    "import pdb "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "## Environment Declaration ##\n",
    "env = gym.make('CartPole-v0')\n",
    "env.seed(0)\n",
    "torch.manual_seed(0)\n",
    "gamma = 0.99 \n",
    "eps = np.finfo(np.float32).eps.item() \n",
    "## for removing numerical instability\n",
    "global_step = 0 \n",
    "tb_folder = './sample_efficiency_2'\n",
    "tb = logger.Logger(tb_folder, name='freeloc') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Policy Network ## \n",
    "class Policy(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Policy, self).__init__()\n",
    "        self.affine1 = nn.Linear(4, 8)\n",
    "        self.affine2 = nn.Linear(8, 2)\n",
    "        \n",
    "        self.saved_log_probs = []\n",
    "        self.rewards = []\n",
    "        \n",
    "        self.policy_file = './policy_model'\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.affine1(x))\n",
    "        action_scores = self.affine2(x)\n",
    "        return F.softmax(action_scores, dim=1)\n",
    "    \n",
    "    def save_model_weights(self):\n",
    "        torch.save(self.state_dict(), self.policy_file)\n",
    "\n",
    "    def load_model_weights(self):\n",
    "        checkpoint_dict = torch.load(self.policy_file)\n",
    "        self.load_state_dict(checkpoint_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Select action based on policy network ## \n",
    "def select_action(policy, state):\n",
    "    state = torch.from_numpy(state).float().unsqueeze(0)\n",
    "    state = Variable(state)\n",
    "    probs = policy(state)\n",
    "    m = Categorical(probs)\n",
    "    action = m.sample()\n",
    "    policy.saved_log_probs.append(m.log_prob(action))\n",
    "    \n",
    "    arr = action.data.numpy() ## Variable to numpy array\n",
    "    return arr[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Update policy network after recording one episode ##\n",
    "def train_policy_network_after_one_episode():\n",
    "    R = 0 \n",
    "    policy_loss = []\n",
    "    rewards = []\n",
    "    for r in policy.rewards[::-1]:\n",
    "        R = r + gamma*R \n",
    "        rewards.insert(0, R)\n",
    "\n",
    "    rewards = torch.Tensor(rewards)\n",
    "    rewards = (rewards - rewards.mean())/(rewards.std() + eps)\n",
    "    for log_prob, reward in zip(policy.saved_log_probs, rewards):\n",
    "        policy_loss.append(-log_prob*reward)\n",
    "    optimizer.zero_grad()\n",
    "    policy_loss = torch.cat(policy_loss).sum()\n",
    "    policy_loss.backward()\n",
    "    optimizer.step()\n",
    "    del policy.rewards[:]\n",
    "    del policy.saved_log_probs[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## trainPolicy for gievn number of episodes either on real episodes or fake episodes ##\n",
    "def trainPolicy(numEpisodes, real=True):\n",
    "    global global_step\n",
    "    for i in range(0, numEpisodes):\n",
    "        \n",
    "        if (real):\n",
    "            state = env.reset()\n",
    "#             real_episodes += 1 \n",
    "        else:\n",
    "            state = np.random.uniform(-0.1,0.1,[4])\n",
    "        done = False\n",
    "        t = 0 \n",
    "\n",
    "        while (not done and t < 200):\n",
    "            action = select_action(policy, state)\n",
    "            t += 1\n",
    "            if (real):\n",
    "                xs.append(state)\n",
    "                action_seq.append(action)\n",
    "                state, reward, done, _ = env.step(action)\n",
    "                next_xs.append(state)\n",
    "                rs.append(reward)\n",
    "                ds.append(done)\n",
    "            else:\n",
    "                next_state_p, reward, done = stepModel(policy, state, action)\n",
    "                state = next_state_p.data.numpy()\n",
    "                state = state[0]\n",
    "                reward = reward.data.numpy()[0][0]\n",
    "                done = done.data.numpy()[0][0]\n",
    "                done = (done > 0.1)\n",
    "            policy.rewards.append(reward)\n",
    "        \n",
    "        train_policy_network_after_one_episode()\n",
    "        if (real):\n",
    "            global_step += 1\n",
    "            if (global_step % 10 == 0):\n",
    "                total_reward = test(20)\n",
    "                tb.scalar_summary('Episode Reward', total_reward, global_step)\n",
    "    print('Episode {}\\t Length of episode {:5d}'.format(i, t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Network to learn model dynamics ### \n",
    "class Model(nn.Module):\n",
    "    \n",
    "    def __init__(self, batch_size = 1):\n",
    "        super(Model, self).__init__()\n",
    "        self.nh = 256\n",
    "        self.last_layer = nn.Sequential(nn.Linear(5, self.nh),\n",
    "                                nn.ReLU(), \n",
    "                                nn.Linear(self.nh, self.nh),\n",
    "                                nn.ReLU())\n",
    "        \n",
    "        self.next_state = nn.Sequential(nn.Linear(self.nh, 4))\n",
    "        self.reward = nn.Sequential(nn.Linear(self.nh, 1))\n",
    "        self.done = nn.Sequential(nn.Linear(self.nh, 1), nn.Sigmoid())\n",
    "        self._loss = None\n",
    "        self.batch_size = batch_size\n",
    "        self.L2loss = nn.MSELoss()\n",
    "        self.terminalLoss = nn.BCELoss() \n",
    "        self.dynamics_file = './dynamics_model'\n",
    "        \n",
    "    @property\n",
    "    def loss(self):\n",
    "        return self._loss \n",
    "        \n",
    "    def forward(self, data, targets):\n",
    "        \n",
    "        ## data would be (state, action)\n",
    "        data = data.view(self.batch_size, 5)\n",
    "        f = self.last_layer(Variable(data))\n",
    "        next_state_p = self.next_state(f)\n",
    "        reward_p = self.reward(f)\n",
    "        done_p = self.done(f)\n",
    "        self._loss = self.build_loss(next_state_p, reward_p, done_p, targets) \n",
    "        return next_state_p, reward_p, done_p\n",
    "\n",
    "    def forward_test(self, data):\n",
    "        \n",
    "        ## data would be (state, action)\n",
    "        ## at test time, it has to be one input\n",
    "        data = data.view(1, 5)\n",
    "        f = self.last_layer(Variable(data))\n",
    "        next_state_p = self.next_state(f)\n",
    "        reward_p = self.reward(f)\n",
    "        done_p = self.done(f)\n",
    "        return next_state_p, reward_p, done_p\n",
    "    \n",
    "    def build_loss(self, next_state_p, reward_p, done_p, targets):\n",
    "        \n",
    "        target_next_state =  Variable(targets[:,0:4])\n",
    "        state_loss = self.L2loss(next_state_p, target_next_state)\n",
    "        target_reward = Variable(targets[:,4])\n",
    "        reward_loss = self.L2loss(reward_p, target_reward) \n",
    "\n",
    "        target_v = Variable(targets[:,5])\n",
    "        done_loss = self.terminalLoss(done_p, target_v)\n",
    "        total_loss = state_loss + reward_loss + done_loss \n",
    "        return total_loss \n",
    "    \n",
    "    def save_model_weights(self):\n",
    "#         pdb.set_trace()\n",
    "        torch.save(self.state_dict(), self.dynamics_file)\n",
    "\n",
    "    def load_model_weights(self):\n",
    "        checkpoint_dict = torch.load(self.dynamics_file)\n",
    "        self.load_state_dict(checkpoint_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## create shuffled dataset for supervised learning ## \n",
    "def create_dataset(xs, action_seq, next_xs, rs, ds):\n",
    "    data = []\n",
    "    targets = []\n",
    "    T = len(xs)\n",
    "    \n",
    "    for j in range(0, T):\n",
    "        state = xs[j]\n",
    "        action = action_seq [j]\n",
    "        x = np.insert(state, 4, action)\n",
    "        x = torch.from_numpy(x).float()\n",
    "        data.append(x)\n",
    "         \n",
    "        done_ = ds[j]*1\n",
    "        state = torch.from_numpy(next_xs[j]).float()\n",
    "        reward = torch.from_numpy(np.array([rs[j]])).float()\n",
    "        done = torch.from_numpy(np.array([done_])).float()\n",
    "        targets.append(torch.cat([state, reward, done]))\n",
    "        \n",
    "    data = torch.stack(data)\n",
    "    targets = torch.stack(targets)\n",
    "    \n",
    "    ## shuffling \n",
    "    shuffle_indices = np.random.choice(data.size(0), data.size(0), replace=False)\n",
    "    shuffle_indices = torch.from_numpy(shuffle_indices).long()\n",
    "    data = data[shuffle_indices, :]\n",
    "    targets = targets[shuffle_indices, :]\n",
    "    \n",
    "    return data, targets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainModel(dynamics_model, data, targets, num_epochs):\n",
    "    \n",
    "    for i in range(num_epochs):\n",
    "        n = data.size(0)\n",
    "        num_steps = int(n/batch_size)\n",
    "\n",
    "        epochs = 5\n",
    "        for i in range(0, epochs):\n",
    "            for j in range(0, num_steps):\n",
    "                next_state, reward_p, done_p = dynamics_model.forward(data[j:j+batch_size], \n",
    "                                                                      targets[j:j+batch_size])\n",
    "                optimizer_model.zero_grad()\n",
    "                loss = dynamics_model.loss.mean()\n",
    "                loss.backward()\n",
    "                optimizer_model.step()\n",
    "        print(loss.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stepModel(policy, state, action):\n",
    "    \n",
    "    x = np.insert(state, 4, action)\n",
    "    x = torch.from_numpy(x).float()\n",
    "    \n",
    "    next_state, reward_p, done_p = dynamics_model.forward_test(x)\n",
    "    \n",
    "    next_state[:,0] = torch.clamp(next_state[:,0], -2.4, 2.4)\n",
    "    next_state[:,2] = torch.clamp(next_state[:,1], -0.4, 0.4)\n",
    "    \n",
    "    return next_state, reward_p, done_p     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "policy = Policy()\n",
    "optimizer = optim.Adam(policy.parameters(), lr=1e-2)\n",
    "\n",
    "batch_size = 5\n",
    "dynamics_model = Model(batch_size=batch_size)\n",
    "optimizer_model = optim.SGD(dynamics_model.parameters(), lr=1e-2)\n",
    "\n",
    "xs = []\n",
    "action_seq = []\n",
    "next_xs = []\n",
    "rs = []\n",
    "ds = []\n",
    "\n",
    "epochs = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(num_episodes):\n",
    "    total_reward = 0.0\n",
    "    for i in range(num_episodes):\n",
    "        s = env.reset()\n",
    "        done = False \n",
    "        while (not done):\n",
    "            action = select_action(policy, s)\n",
    "            s, reward, done, _ = env.step(action)\n",
    "            total_reward += reward \n",
    "    return (total_reward/num_episodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 99\t Length of episode    75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aashi/penv/lib/python3.5/site-packages/torch/nn/functional.py:1189: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([5, 1])) is deprecated. Please ensure they have the same size.\n",
      "  \"Please ensure they have the same size.\".format(target.size(), input.size()))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1.00000e-02 *\n",
      "  3.5323\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "\n",
      "1.00000e-02 *\n",
      "  3.6718\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "\n",
      "1.00000e-02 *\n",
      "  3.2345\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Episode 39\t Length of episode    19\n",
      "100 51.25\n",
      "Episode 19\t Length of episode    76\n",
      "\n",
      "1.00000e-03 *\n",
      "  9.0213\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "\n",
      "1.00000e-03 *\n",
      "  8.7696\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "\n",
      "1.00000e-03 *\n",
      "  8.2837\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "120 77.75\n",
      "Episode 39\t Length of episode   200\n",
      "120 52.55\n",
      "Episode 19\t Length of episode    42\n",
      "\n",
      " 0.1036\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "\n",
      " 0.1079\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "\n",
      " 0.1052\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "140 59.5\n",
      "Episode 39\t Length of episode    37\n",
      "140 150.2\n",
      "Episode 19\t Length of episode   200\n",
      "\n",
      "1.00000e-04 *\n",
      "  7.0667\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "\n",
      "1.00000e-04 *\n",
      "  5.7576\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "\n",
      "1.00000e-04 *\n",
      "  4.4987\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "160 148.8\n",
      "Episode 39\t Length of episode   200\n",
      "160 186.0\n",
      "Episode 19\t Length of episode   101\n",
      "\n",
      "1.00000e-03 *\n",
      "  8.1763\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "\n",
      "1.00000e-03 *\n",
      "  6.2918\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "\n",
      "1.00000e-03 *\n",
      "  5.2182\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "180 140.95\n",
      "Episode 39\t Length of episode   200\n",
      "180 128.65\n",
      "Episode 19\t Length of episode   200\n",
      "\n",
      "1.00000e-03 *\n",
      "  3.7708\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "\n",
      "1.00000e-03 *\n",
      "  2.7943\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "\n",
      "1.00000e-03 *\n",
      "  2.2782\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "200 193.9\n",
      "Episode 39\t Length of episode   200\n",
      "200 172.65\n",
      "Episode 19\t Length of episode   200\n",
      "\n",
      "1.00000e-03 *\n",
      "  3.4736\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "\n",
      "1.00000e-03 *\n",
      "  4.6713\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "\n",
      "1.00000e-03 *\n",
      "  5.2605\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "220 176.8\n",
      "Episode 39\t Length of episode   200\n",
      "220 140.15\n",
      "Episode 19\t Length of episode   171\n",
      "\n",
      "1.00000e-04 *\n",
      "  7.6092\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "\n",
      "1.00000e-04 *\n",
      "  3.9972\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "\n",
      "1.00000e-04 *\n",
      "  2.6265\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "240 148.55\n",
      "Episode 39\t Length of episode   200\n",
      "240 63.05\n",
      "Episode 19\t Length of episode    12\n",
      "\n",
      "1.00000e-03 *\n",
      "  3.5025\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "\n",
      "1.00000e-03 *\n",
      "  2.8490\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "\n",
      "1.00000e-03 *\n",
      "  2.4044\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "260 22.4\n",
      "Episode 39\t Length of episode   200\n",
      "260 32.65\n",
      "Episode 19\t Length of episode   102\n",
      "\n",
      "1.00000e-02 *\n",
      "  5.5896\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "\n",
      "1.00000e-02 *\n",
      "  3.6477\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "\n",
      "1.00000e-02 *\n",
      "  2.8329\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "280 105.5\n",
      "Episode 39\t Length of episode    64\n",
      "280 184.65\n",
      "Episode 19\t Length of episode   200\n",
      "\n",
      "1.00000e-03 *\n",
      "  2.0371\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "\n",
      "1.00000e-03 *\n",
      "  1.8548\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "\n",
      "1.00000e-03 *\n",
      "  1.4495\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "300 200.0\n",
      "True\n",
      "Episode 39\t Length of episode   200\n",
      "300 200.0\n",
      "True\n",
      "Episode 19\t Length of episode   200\n",
      "\n",
      "1.00000e-03 *\n",
      "  6.2160\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "\n",
      "1.00000e-03 *\n",
      "  6.4867\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "\n",
      "1.00000e-03 *\n",
      "  6.5843\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "320 200.0\n",
      "True\n",
      "Episode 39\t Length of episode   200\n",
      "320 196.45\n",
      "True\n",
      "Episode 19\t Length of episode   200\n",
      "\n",
      "1.00000e-04 *\n",
      "  1.6790\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "\n",
      "1.00000e-04 *\n",
      "  1.4928\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "\n",
      "1.00000e-04 *\n",
      "  1.2969\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "340 187.9\n",
      "Episode 39\t Length of episode   200\n",
      "340 193.6\n",
      "Episode 19\t Length of episode   200\n",
      "\n",
      "1.00000e-02 *\n",
      "  2.4493\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "\n",
      "1.00000e-02 *\n",
      "  2.0458\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "\n",
      "1.00000e-02 *\n",
      "  1.9418\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "360 198.7\n",
      "True\n",
      "Episode 39\t Length of episode    20\n",
      "360 198.2\n",
      "True\n",
      "Episode 19\t Length of episode   200\n",
      "\n",
      "1.00000e-03 *\n",
      "  3.3273\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "\n",
      "1.00000e-03 *\n",
      "  3.4673\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "\n",
      "1.00000e-03 *\n",
      "  3.4540\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "380 200.0\n",
      "True\n",
      "Episode 39\t Length of episode    46\n",
      "380 198.1\n",
      "True\n",
      "Episode 19\t Length of episode   135\n",
      "\n",
      "1.00000e-04 *\n",
      "  5.8547\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "\n",
      "1.00000e-04 *\n",
      "  3.9972\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "\n",
      "1.00000e-04 *\n",
      "  3.1199\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "400 150.75\n",
      "Episode 39\t Length of episode    39\n",
      "400 190.75\n",
      "Episode 19\t Length of episode   200\n",
      "\n",
      "1.00000e-03 *\n",
      "  1.5330\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "\n",
      "1.00000e-03 *\n",
      "  1.5584\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "\n",
      "1.00000e-03 *\n",
      "  1.4774\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "420 200.0\n",
      "True\n",
      "Episode 39\t Length of episode    48\n",
      "420 200.0\n",
      "True\n",
      "Episode 19\t Length of episode   200\n",
      "\n",
      "1.00000e-03 *\n",
      "  5.2498\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "\n",
      "1.00000e-03 *\n",
      "  5.3395\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "\n",
      "1.00000e-03 *\n",
      "  5.3665\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "440 200.0\n",
      "True\n",
      "Episode 39\t Length of episode    13\n",
      "440 197.1\n",
      "True\n",
      "Episode 19\t Length of episode   200\n",
      "\n",
      "1.00000e-03 *\n",
      "  1.5424\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "\n",
      "1.00000e-03 *\n",
      "  1.6279\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "\n",
      "1.00000e-03 *\n",
      "  1.6702\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "460 200.0\n",
      "True\n",
      "Episode 39\t Length of episode    84\n",
      "460 183.95\n",
      "Episode 19\t Length of episode   200\n",
      "\n",
      "1.00000e-03 *\n",
      "  2.5676\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "\n",
      "1.00000e-03 *\n",
      "  2.3895\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "\n",
      "1.00000e-03 *\n",
      "  2.1204\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "480 181.8\n",
      "Episode 39\t Length of episode    31\n",
      "480 179.8\n",
      "Episode 19\t Length of episode   200\n",
      "\n",
      "1.00000e-03 *\n",
      "  1.5548\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "\n",
      "1.00000e-03 *\n",
      "  1.6117\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "\n",
      "1.00000e-03 *\n",
      "  1.5132\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "500 198.5\n",
      "True\n",
      "Episode 39\t Length of episode    91\n",
      "500 176.25\n",
      "Episode 19\t Length of episode   132\n",
      "\n",
      "1.00000e-03 *\n",
      "  2.1066\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "\n",
      "1.00000e-03 *\n",
      "  1.8418\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "\n",
      "1.00000e-03 *\n",
      "  1.5212\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "520 144.75\n",
      "Episode 39\t Length of episode   200\n",
      "520 129.45\n",
      "Episode 19\t Length of episode   121\n",
      "\n",
      " 0.5345\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "\n",
      " 0.4914\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "\n",
      " 0.4762\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "540 132.15\n",
      "Episode 39\t Length of episode   200\n",
      "540 194.35\n",
      "Episode 19\t Length of episode   115\n",
      "\n",
      "1.00000e-03 *\n",
      "  7.0521\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "\n",
      "1.00000e-03 *\n",
      "  2.8400\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "\n",
      "1.00000e-03 *\n",
      "  1.4045\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "560 176.95\n",
      "Episode 39\t Length of episode   200\n",
      "560 111.6\n",
      "Episode 19\t Length of episode   137\n",
      "\n",
      "1.00000e-02 *\n",
      "  1.0744\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "\n",
      "1.00000e-02 *\n",
      "  1.0464\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "\n",
      "1.00000e-02 *\n",
      "  1.0596\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "580 121.75\n",
      "Episode 39\t Length of episode    14\n",
      "580 133.65\n",
      "Episode 19\t Length of episode   200\n",
      "\n",
      "1.00000e-04 *\n",
      "  5.4262\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "\n",
      "1.00000e-04 *\n",
      "  2.9526\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "\n",
      "1.00000e-04 *\n",
      "  2.1706\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "600 200.0\n",
      "True\n",
      "Episode 39\t Length of episode   200\n",
      "600 170.85\n",
      "Episode 19\t Length of episode   198\n",
      "\n",
      "1.00000e-04 *\n",
      "  2.2788\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "\n",
      "1.00000e-04 *\n",
      "  2.2912\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "\n",
      "1.00000e-04 *\n",
      "  2.4614\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "620 135.5\n",
      "Episode 39\t Length of episode   200\n",
      "620 122.05\n",
      "Episode 19\t Length of episode    27\n",
      "\n",
      "1.00000e-04 *\n",
      "  9.5582\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "\n",
      "1.00000e-04 *\n",
      "  8.7185\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "\n",
      "1.00000e-04 *\n",
      "  7.7263\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "640 167.0\n",
      "Episode 39\t Length of episode   200\n",
      "640 171.3\n",
      "Episode 19\t Length of episode   200\n",
      "\n",
      "1.00000e-05 *\n",
      "  8.9443\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "\n",
      "1.00000e-05 *\n",
      "  7.9106\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "\n",
      "1.00000e-05 *\n",
      "  7.6117\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "660 162.85\n",
      "Episode 39\t Length of episode   103\n",
      "660 176.7\n",
      "Episode 19\t Length of episode   200\n",
      "\n",
      "1.00000e-03 *\n",
      "  2.9279\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "\n",
      "1.00000e-03 *\n",
      "  3.6494\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "\n",
      "1.00000e-03 *\n",
      "  4.0460\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "680 184.6\n",
      "Episode 39\t Length of episode   200\n",
      "680 186.5\n",
      "Episode 19\t Length of episode   144\n",
      "\n",
      "1.00000e-03 *\n",
      "  2.5785\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "\n",
      "1.00000e-03 *\n",
      "  2.5922\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "\n",
      "1.00000e-03 *\n",
      "  2.5167\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "700 188.85\n",
      "Episode 39\t Length of episode   200\n",
      "700 195.75\n",
      "True\n",
      "Episode 19\t Length of episode   130\n",
      "\n",
      "1.00000e-03 *\n",
      "  2.5173\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "\n",
      "1.00000e-03 *\n",
      "  1.6835\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "\n",
      "1.00000e-03 *\n",
      "  1.2166\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "720 156.4\n",
      "Episode 39\t Length of episode    35\n",
      "720 32.45\n",
      "Episode 19\t Length of episode    96\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1.00000e-04 *\n",
      "  1.4184\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "\n",
      "1.00000e-04 *\n",
      "  1.1561\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "\n",
      "1.00000e-04 *\n",
      "  1.0282\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "740 67.6\n",
      "Episode 39\t Length of episode   200\n",
      "740 103.05\n",
      "Episode 19\t Length of episode    45\n",
      "\n",
      "1.00000e-04 *\n",
      "  6.1900\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "\n",
      "1.00000e-04 *\n",
      "  6.3697\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "\n",
      "1.00000e-04 *\n",
      "  6.1158\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "760 131.9\n",
      "Episode 39\t Length of episode   200\n",
      "760 89.35\n",
      "Episode 19\t Length of episode    19\n",
      "\n",
      "1.00000e-02 *\n",
      "  2.7599\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "\n",
      "1.00000e-02 *\n",
      "  2.7345\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "\n",
      "1.00000e-02 *\n",
      "  2.6736\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "780 72.5\n",
      "Episode 39\t Length of episode   200\n",
      "780 101.7\n",
      "Episode 19\t Length of episode   163\n",
      "\n",
      "1.00000e-03 *\n",
      "  2.2890\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "\n",
      "1.00000e-03 *\n",
      "  2.0862\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "\n",
      "1.00000e-03 *\n",
      "  2.2014\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "800 139.0\n",
      "Episode 39\t Length of episode   200\n",
      "800 200.0\n",
      "True\n",
      "Episode 19\t Length of episode   200\n",
      "\n",
      "1.00000e-04 *\n",
      "  2.0816\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "\n",
      "1.00000e-04 *\n",
      "  1.7942\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "\n",
      "1.00000e-04 *\n",
      "  1.4989\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "820 197.1\n",
      "True\n",
      "Episode 39\t Length of episode   200\n",
      "820 199.85\n",
      "True\n",
      "Episode 19\t Length of episode   200\n",
      "\n",
      "1.00000e-03 *\n",
      "  1.0621\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "\n",
      "1.00000e-04 *\n",
      "  9.6579\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "\n",
      "1.00000e-04 *\n",
      "  8.7602\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "840 200.0\n",
      "True\n",
      "Episode 39\t Length of episode   200\n",
      "840 191.5\n",
      "Episode 19\t Length of episode   200\n",
      "\n",
      "1.00000e-05 *\n",
      "  3.8235\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "\n",
      "1.00000e-05 *\n",
      "  4.2564\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "\n",
      "1.00000e-05 *\n",
      "  3.9756\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "860 184.95\n",
      "Episode 39\t Length of episode   200\n",
      "860 198.55\n",
      "True\n",
      "Episode 19\t Length of episode   200\n",
      "\n",
      "1.00000e-03 *\n",
      "  8.9074\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "\n",
      "1.00000e-03 *\n",
      "  5.1964\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "\n",
      "1.00000e-03 *\n",
      "  4.0788\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "880 200.0\n",
      "True\n",
      "Episode 39\t Length of episode   200\n",
      "880 200.0\n",
      "True\n",
      "Episode 19\t Length of episode    70\n",
      "\n",
      "1.00000e-03 *\n",
      "  3.9708\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "\n",
      "1.00000e-03 *\n",
      "  2.7028\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "\n",
      "1.00000e-03 *\n",
      "  2.1934\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "900 200.0\n",
      "True\n",
      "Episode 39\t Length of episode   200\n",
      "900 189.4\n",
      "Episode 19\t Length of episode   124\n",
      "\n",
      "1.00000e-03 *\n",
      "  1.0166\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "\n",
      "1.00000e-03 *\n",
      "  2.1106\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "\n",
      "1.00000e-03 *\n",
      "  3.0297\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "920 200.0\n",
      "True\n",
      "Episode 39\t Length of episode   200\n",
      "920 200.0\n",
      "True\n",
      "Episode 19\t Length of episode   200\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-784b44a8decc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0mreal_episodes\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction_seq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnext_xs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m         \u001b[0mtrainModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdynamics_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m         \u001b[0mpolicy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_model_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0mdynamics_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_model_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-91ade4572246>\u001b[0m in \u001b[0;36mtrainModel\u001b[0;34m(dynamics_model, data, targets, num_epochs)\u001b[0m\n\u001b[1;32m     12\u001b[0m                 \u001b[0moptimizer_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdynamics_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m                 \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m                 \u001b[0moptimizer_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/penv/lib/python3.5/site-packages/torch/autograd/variable.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, retain_variables)\u001b[0m\n\u001b[1;32m    165\u001b[0m                 \u001b[0mVariable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m         \"\"\"\n\u001b[0;32m--> 167\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    168\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/penv/lib/python3.5/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(variables, grad_variables, retain_graph, create_graph, retain_variables)\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[0;32m---> 99\u001b[0;31m         variables, grad_variables, retain_graph)\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "real_episodes = 0 \n",
    "trainPolicy(100)\n",
    "real_episodes += 100 \n",
    "data, targets = create_dataset(xs, action_seq, next_xs, rs, ds)\n",
    "trainModel(dynamics_model, data, targets, epochs)\n",
    "## Model trained on initial 100 real episodes ##\n",
    "# total_reward = test(20)\n",
    "# tb.scalar_summary('Episode Reward', total_reward, global_step)\n",
    "## Alternate between model training and improving policy ## \n",
    "i = 0 \n",
    "\n",
    "solved = False \n",
    "\n",
    "# while (not solved):\n",
    "for i in range(500):\n",
    "    if (i % 2 == 0):\n",
    "        ## 20 fake episodes\n",
    "        trainPolicy(40, False)\n",
    "        \n",
    "    else:\n",
    "        ## real episodes\n",
    "        xs = []\n",
    "        action_seq = []\n",
    "        next_xs = []\n",
    "        rs = []\n",
    "        ds = []\n",
    "        trainPolicy(20, True)\n",
    "        real_episodes += 20 \n",
    "        data, targets = create_dataset(xs, action_seq, next_xs, rs, ds)\n",
    "        trainModel(dynamics_model, data, targets, epochs)\n",
    "        policy.save_model_weights()\n",
    "        dynamics_model.save_model_weights()\n",
    "    i += 1\n",
    "    total_reward = test(20)\n",
    "#     tb.scalar_summary('Episode Reward', total_reward, global_step)\n",
    "    print (real_episodes, total_reward)\n",
    "    if (total_reward >= 195):\n",
    "        solved = True \n",
    "        print (solved)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aashi/penv/lib/python3.5/site-packages/matplotlib/cbook/deprecation.py:106: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  warnings.warn(message, mplDeprecation, stacklevel=1)\n",
      "/home/aashi/penv/lib/python3.5/site-packages/matplotlib/legend.py:936: UserWarning: Legend does not support [<matplotlib.lines.Line2D object at 0x7f34696e8b38>] instances.\n",
      "A proxy artist may be used instead.\n",
      "See: http://matplotlib.org/users/legend_guide.html#creating-artists-specifically-for-adding-to-the-legend-aka-proxy-artists\n",
      "  \"aka-proxy-artists\".format(orig_handle)\n",
      "/home/aashi/penv/lib/python3.5/site-packages/matplotlib/legend.py:936: UserWarning: Legend does not support [<matplotlib.lines.Line2D object at 0x7f34696e8fd0>] instances.\n",
      "A proxy artist may be used instead.\n",
      "See: http://matplotlib.org/users/legend_guide.html#creating-artists-specifically-for-adding-to-the-legend-aka-proxy-artists\n",
      "  \"aka-proxy-artists\".format(orig_handle)\n",
      "/home/aashi/penv/lib/python3.5/site-packages/matplotlib/legend.py:936: UserWarning: Legend does not support [<matplotlib.lines.Line2D object at 0x7f3469693860>] instances.\n",
      "A proxy artist may be used instead.\n",
      "See: http://matplotlib.org/users/legend_guide.html#creating-artists-specifically-for-adding-to-the-legend-aka-proxy-artists\n",
      "  \"aka-proxy-artists\".format(orig_handle)\n",
      "/home/aashi/penv/lib/python3.5/site-packages/matplotlib/legend.py:936: UserWarning: Legend does not support [<matplotlib.lines.Line2D object at 0x7f3469693da0>] instances.\n",
      "A proxy artist may be used instead.\n",
      "See: http://matplotlib.org/users/legend_guide.html#creating-artists-specifically-for-adding-to-the-legend-aka-proxy-artists\n",
      "  \"aka-proxy-artists\".format(orig_handle)\n",
      "/home/aashi/penv/lib/python3.5/site-packages/matplotlib/legend.py:936: UserWarning: Legend does not support [<matplotlib.lines.Line2D object at 0x7f34696b9588>] instances.\n",
      "A proxy artist may be used instead.\n",
      "See: http://matplotlib.org/users/legend_guide.html#creating-artists-specifically-for-adding-to-the-legend-aka-proxy-artists\n",
      "  \"aka-proxy-artists\".format(orig_handle)\n",
      "/home/aashi/penv/lib/python3.5/site-packages/matplotlib/legend.py:936: UserWarning: Legend does not support [<matplotlib.lines.Line2D object at 0x7f34696b9ac8>] instances.\n",
      "A proxy artist may be used instead.\n",
      "See: http://matplotlib.org/users/legend_guide.html#creating-artists-specifically-for-adding-to-the-legend-aka-proxy-artists\n",
      "  \"aka-proxy-artists\".format(orig_handle)\n",
      "/home/aashi/penv/lib/python3.5/site-packages/matplotlib/legend.py:936: UserWarning: Legend does not support [<matplotlib.lines.Line2D object at 0x7f3469664278>] instances.\n",
      "A proxy artist may be used instead.\n",
      "See: http://matplotlib.org/users/legend_guide.html#creating-artists-specifically-for-adding-to-the-legend-aka-proxy-artists\n",
      "  \"aka-proxy-artists\".format(orig_handle)\n",
      "/home/aashi/penv/lib/python3.5/site-packages/matplotlib/legend.py:936: UserWarning: Legend does not support [<matplotlib.lines.Line2D object at 0x7f34696647b8>] instances.\n",
      "A proxy artist may be used instead.\n",
      "See: http://matplotlib.org/users/legend_guide.html#creating-artists-specifically-for-adding-to-the-legend-aka-proxy-artists\n",
      "  \"aka-proxy-artists\".format(orig_handle)\n",
      "/home/aashi/penv/lib/python3.5/site-packages/matplotlib/legend.py:936: UserWarning: Legend does not support [<matplotlib.lines.Line2D object at 0x7f3469602c50>] instances.\n",
      "A proxy artist may be used instead.\n",
      "See: http://matplotlib.org/users/legend_guide.html#creating-artists-specifically-for-adding-to-the-legend-aka-proxy-artists\n",
      "  \"aka-proxy-artists\".format(orig_handle)\n",
      "/home/aashi/penv/lib/python3.5/site-packages/matplotlib/legend.py:936: UserWarning: Legend does not support [<matplotlib.lines.Line2D object at 0x7f346960a1d0>] instances.\n",
      "A proxy artist may be used instead.\n",
      "See: http://matplotlib.org/users/legend_guide.html#creating-artists-specifically-for-adding-to-the-legend-aka-proxy-artists\n",
      "  \"aka-proxy-artists\".format(orig_handle)\n",
      "/home/aashi/penv/lib/python3.5/site-packages/matplotlib/legend.py:936: UserWarning: Legend does not support [<matplotlib.lines.Line2D object at 0x7f346962bc18>] instances.\n",
      "A proxy artist may be used instead.\n",
      "See: http://matplotlib.org/users/legend_guide.html#creating-artists-specifically-for-adding-to-the-legend-aka-proxy-artists\n",
      "  \"aka-proxy-artists\".format(orig_handle)\n",
      "/home/aashi/penv/lib/python3.5/site-packages/matplotlib/legend.py:936: UserWarning: Legend does not support [<matplotlib.lines.Line2D object at 0x7f34696dd518>] instances.\n",
      "A proxy artist may be used instead.\n",
      "See: http://matplotlib.org/users/legend_guide.html#creating-artists-specifically-for-adding-to-the-legend-aka-proxy-artists\n",
      "  \"aka-proxy-artists\".format(orig_handle)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f34696dda90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "policy.load_model_weights()\n",
    "dynamics_model.load_model_weights()\n",
    "\n",
    "policy.eval()\n",
    "dynamics_model.eval()\n",
    "\n",
    "%matplotlib inline \n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "### Plot the curves of predicted states ### \n",
    "### Run one episodes to compare predictions and ground truth ###\n",
    "s = env.reset()\n",
    "d = False \n",
    "pState = np.zeros((200, 6))\n",
    "tState = np.zeros((200, 6))\n",
    "i = 0 \n",
    "while (not d):\n",
    "    action = select_action(policy, s)\n",
    "    nS, r, d, _ = env.step(action)\n",
    "    tState[i,0] = nS[0]\n",
    "    tState[i,1] = nS[1]\n",
    "    tState[i,2] = nS[2]\n",
    "    tState[i,3] = nS[3]\n",
    "    tState[i,4] = r \n",
    "    tState[i,5] = d*1 \n",
    "    i+=1\n",
    "    print (i)\n",
    "    next_state_p, reward, done = stepModel(policy, s, action)\n",
    "    state = next_state_p.data.numpy()\n",
    "    state = state[0]\n",
    "    reward = reward.data.numpy()[0][0]\n",
    "    done = done.data.numpy()[0][0]\n",
    "    done = (done > 0.1)\n",
    "    \n",
    "    pState[i,0] = state[0]\n",
    "    pState[i,1] = state[1]\n",
    "    pState[i,2] = state[2]\n",
    "    pState[i,3] = state[3]\n",
    "    pState[i,4] = reward \n",
    "    pState[i,5] = done*1 \n",
    "\n",
    "plt.figure(figsize=(8, 12))\n",
    "for i in range(6):\n",
    "    plt.subplot(6, 2, 2*i + 1)\n",
    "    predicted = plt.plot(pState[:,i], label='Predicted value')\n",
    "    plt.subplot(6,2,2*i+1)\n",
    "    true = plt.plot(tState[:,i], label='True value')\n",
    "    plt.legend([predicted, true], ['Predicted value', 'True value'])\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tState)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (total_reward)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
