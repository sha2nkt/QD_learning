{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aashi/penv/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.distributions import Categorical\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import gym\n",
    "import numpy as np\n",
    "from itertools import count\n",
    "\n",
    "import pdb \n",
    "\n",
    "import logger "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "env = gym.make('CartPole-v0')\n",
    "env.seed(0)\n",
    "torch.manual_seed(0)\n",
    "gamma = 0.99 \n",
    "eps = np.finfo(np.float32).eps.item() \n",
    "## for removing numerical instability\n",
    "\n",
    "global_step = 0 \n",
    "tb_folder = './reinforce_only'\n",
    "tb = logger.Logger(tb_folder, name='freeloc') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Policy(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Policy, self).__init__()\n",
    "        self.affine1 = nn.Linear(4, 8)\n",
    "        self.affine2 = nn.Linear(8, 2)\n",
    "        \n",
    "        self.saved_log_probs = []\n",
    "        self.rewards = []\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.affine1(x))\n",
    "        action_scores = self.affine2(x)\n",
    "        return F.softmax(action_scores, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "policy = Policy()\n",
    "optimizer = optim.Adam(policy.parameters(), lr=1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_action(state):\n",
    "    state = torch.from_numpy(state).float().unsqueeze(0)\n",
    "    state = Variable(state)\n",
    "    probs = policy(state)\n",
    "    m = Categorical(probs)\n",
    "    action = m.sample()\n",
    "    policy.saved_log_probs.append(m.log_prob(action))\n",
    "#     pdb.set_trace()\n",
    "    \n",
    "    arr = action.data.numpy() ## Variable to numpy array\n",
    "    return arr[0]\n",
    "#     return action.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def finish_episode():\n",
    "    R = 0 \n",
    "    policy_loss = []\n",
    "    rewards = []\n",
    "    for r in policy.rewards[::-1]:\n",
    "        R = r + gamma*R \n",
    "        rewards.insert(0, R)\n",
    "#     pdb.set_trace()\n",
    "    rewards = torch.Tensor(rewards)\n",
    "    rewards = (rewards - rewards.mean())/(rewards.std() + eps)\n",
    "    for log_prob, reward in zip(policy.saved_log_probs, rewards):\n",
    "        policy_loss.append(-log_prob*reward)\n",
    "    optimizer.zero_grad()\n",
    "    policy_loss = torch.cat(policy_loss).sum()\n",
    "    policy_loss.backward()\n",
    "    optimizer.step()\n",
    "    del policy.rewards[:]\n",
    "    del policy.saved_log_probs[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    global global_step \n",
    "    stable = 0 \n",
    "    ## count arguments start, [step]\n",
    "    for i_episode in count(1):\n",
    "        state = env.reset()\n",
    "        done = False\n",
    "        t = 0 \n",
    "        while (not done):\n",
    "            action = select_action(state)\n",
    "            t += 1 \n",
    "            state, reward, done, _ = env.step(action)\n",
    "            policy.rewards.append(reward)\n",
    "            \n",
    "        finish_episode()\n",
    "        global_step += 1 \n",
    "        \n",
    "        tb.scalar_summary('Episode Reward', t, global_step)\n",
    "            \n",
    "        if i_episode % 50 == 0:\n",
    "            print('Episode {}\\t Length of episode {:5d}'.format(i_episode, t))\n",
    "\n",
    "        if t >= 195:\n",
    "            stable += 1\n",
    "        else:\n",
    "            stable = 0\n",
    "        \n",
    "        if (stable >= 20):\n",
    "            print(i_episode)\n",
    "            print(\"Solved\")\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 50\t Length of episode    27\n",
      "Episode 100\t Length of episode    19\n",
      "Episode 150\t Length of episode    15\n",
      "Episode 200\t Length of episode    98\n",
      "Episode 250\t Length of episode   191\n",
      "Episode 300\t Length of episode   190\n",
      "Episode 350\t Length of episode   200\n",
      "Episode 400\t Length of episode   132\n",
      "Episode 450\t Length of episode   189\n",
      "Episode 500\t Length of episode   118\n",
      "Episode 550\t Length of episode   200\n",
      "559\n",
      "Solved\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
